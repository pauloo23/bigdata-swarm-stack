{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77ac068d-7d3b-459d-b40d-f2ce7fbdf31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark version: 3.5.0\n",
      "http://minio:9000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from pyspark.sql.types import DoubleType, IntegerType\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "s3_url: str = \"http://minio:9000\"\n",
    "s3_access_key: str = \"minioadmin\"\n",
    "s3_secret_key: str =\"minioadmin\"\n",
    "spark_master_url: str = \"spark://spark-master:7077\"\n",
    "\n",
    "conf = SparkConf()\n",
    "\n",
    "conf.set('spark.hadoop.fs.s3a.endpoint', s3_url)\n",
    "conf.set('spark.hadoop.fs.s3a.access.key', s3_access_key)\n",
    "conf.set('spark.hadoop.fs.s3a.secret.key', s3_secret_key)\n",
    "conf.set('spark.hadoop.fs.s3a.impl', 'org.apache.hadoop.fs.s3a.S3AFileSystem')\n",
    "conf.set('spark.hadoop.fs.s3a.path.style.access', 'true')\n",
    "conf.set('spark.jars.packages', 'org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.262,io.delta:delta-spark_2.12:3.2.0,io.delta:delta-storage:3.2.0')\n",
    "conf.set(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\n",
    "conf.set(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "conf.set(\"spark.sql.warehouse.dir\", \"s3a://data/warehouse\")\n",
    "conf.set(\"spark.hadoop.fs.s3a.connection.ssl.enabled\", \"false\")\n",
    "conf.set(\"hive.metastore.uris\", \"thrift://hive-metastore:9083\")\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName('spark-minio2')\n",
    "    .master(spark_master_url)\n",
    "    .config(conf=conf)\n",
    "    .enableHiveSupport()\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "print(f'spark version: {spark.version}')\n",
    "print(spark._jsc.hadoopConfiguration().get('fs.s3a.endpoint'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d91a8d1d-58b4-40c7-972a-b5255bdd95ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema:\n",
      "root\n",
      " |-- PM2.5 (µg/m³): string (nullable = true)\n",
      " |-- PM10 (µg/m³): string (nullable = true)\n",
      " |-- NO2 (µg/m³): string (nullable = true)\n",
      " |-- SO2 (µg/m³): string (nullable = true)\n",
      " |-- CO (mg/m³): string (nullable = true)\n",
      " |-- O3 (µg/m³): string (nullable = true)\n",
      " |-- Temperature (°C): string (nullable = true)\n",
      " |-- Humidity (%): string (nullable = true)\n",
      " |-- Wind Speed (m/s): string (nullable = true)\n",
      " |-- Wind Direction (°): string (nullable = true)\n",
      " |-- Pressure (hPa): string (nullable = true)\n",
      " |-- Precipitation (mm): string (nullable = true)\n",
      " |-- Visibility (km): string (nullable = true)\n",
      " |-- AQI: string (nullable = true)\n",
      " |-- Season: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Latitude: string (nullable = true)\n",
      " |-- Longitude: string (nullable = true)\n",
      " |-- Day of Week: string (nullable = true)\n",
      " |-- Hour: string (nullable = true)\n",
      " |-- Month: string (nullable = true)\n",
      " |-- Year: string (nullable = true)\n",
      " |-- Weather Condition: string (nullable = true)\n",
      " |-- Station ID: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "source_bucket = \"data\"\n",
    "\n",
    "input_path = f\"s3a://{source_bucket}/air_pollution_china.csv\"\n",
    "delta_path = f\"s3a://{source_bucket}/delta/data/tables/\"\n",
    "df = spark.read.option(\"header\", \"true\").csv(input_path)\n",
    "# Print the schema\n",
    "print(\"Schema:\")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15eae27e-a416-4530-a3cf-7f7eeea0457e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS chinaAirPolution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd11ecfe-2887-49cd-825e-d0ec96f3916f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean schema:\n",
      "root\n",
      " |-- PM25_µg_m³: string (nullable = true)\n",
      " |-- PM10_µg_m³: string (nullable = true)\n",
      " |-- NO2_µg_m³: string (nullable = true)\n",
      " |-- SO2_µg_m³: string (nullable = true)\n",
      " |-- CO_mg_m³: string (nullable = true)\n",
      " |-- O3_µg_m³: string (nullable = true)\n",
      " |-- Temperature_°C: string (nullable = true)\n",
      " |-- Humidity_pct: string (nullable = true)\n",
      " |-- Wind_Speed_m_s: string (nullable = true)\n",
      " |-- Wind_Direction_°: string (nullable = true)\n",
      " |-- Pressure_hPa: string (nullable = true)\n",
      " |-- Precipitation_mm: string (nullable = true)\n",
      " |-- Visibility_km: string (nullable = true)\n",
      " |-- AQI: string (nullable = true)\n",
      " |-- Season: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Latitude: string (nullable = true)\n",
      " |-- Longitude: string (nullable = true)\n",
      " |-- Day_of_Week: string (nullable = true)\n",
      " |-- Hour: string (nullable = true)\n",
      " |-- Month: string (nullable = true)\n",
      " |-- Year: string (nullable = true)\n",
      " |-- Weather_Condition: string (nullable = true)\n",
      " |-- Station_ID: string (nullable = true)\n",
      "\n",
      "Data successfully written to Delta Lake table 'china_air_pollution'\n"
     ]
    }
   ],
   "source": [
    "# Create a clean column name mapping\n",
    "source_columns = df.columns\n",
    "clean_columns = [col_name.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\").replace(\".\", \"\").replace(\"/\", \"_\").replace(\"%\", \"pct\") for col_name in source_columns]\n",
    "\n",
    "# Create a new dataframe with clean column names\n",
    "df_clean = df\n",
    "for i, col_name in enumerate(source_columns):\n",
    "    df_clean = df_clean.withColumnRenamed(col_name, clean_columns[i])\n",
    "\n",
    "# Show the new schema\n",
    "print(\"Clean schema:\")\n",
    "df_clean.printSchema()\n",
    "\n",
    "# List of columns that should be numeric\n",
    "numeric_cols = [\n",
    "    'PM25_µg_m³', 'PM10_µg_m³', 'NO2_µg_m³', 'SO2_µg_m³', \n",
    "    'CO_mg_m³', 'O3_µg_m³', 'Temperature_°C', 'Humidity_pct', \n",
    "    'Wind_Speed_m_s', 'Wind_Direction_°', 'Pressure_hPa', \n",
    "    'Precipitation_mm', 'Visibility_km', 'AQI', \n",
    "    'Latitude', 'Longitude', 'Hour', 'Month', 'Year'\n",
    "]\n",
    "\n",
    "# Convert to appropriate types\n",
    "for column in numeric_cols:\n",
    "    df_clean = df_clean.withColumn(column, F.col(column).cast(DoubleType()))\n",
    "\n",
    "# Now write to Delta format\n",
    "df_clean.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"path\", f'{delta_path}/china_air_pollution') \\\n",
    "    .saveAsTable(\"chinaAirPolution.china_air_pollution\")\n",
    "\n",
    "print(\"Data successfully written to Delta Lake table 'china_air_pollution'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e30fac92-b6a1-4138-8345-03501073c730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------------+-----------------+------------------+------------------+------------------+-----------------+------------------+-----------------+------------------+-----------------+------------------+------------------+----+------+--------+------------------+------------------+-----------+----+-----+------+-----------------+----------+\n",
      "|PM25_µg_m³       |PM10_µg_m³        |NO2_µg_m³        |SO2_µg_m³         |CO_mg_m³          |O3_µg_m³          |Temperature_°C   |Humidity_pct      |Wind_Speed_m_s   |Wind_Direction_°  |Pressure_hPa     |Precipitation_mm  |Visibility_km     |AQI |Season|City    |Latitude          |Longitude         |Day_of_Week|Hour|Month|Year  |Weather_Condition|Station_ID|\n",
      "+-----------------+------------------+-----------------+------------------+------------------+------------------+-----------------+------------------+-----------------+------------------+-----------------+------------------+------------------+----+------+--------+------------------+------------------+-----------+----+-----+------+-----------------+----------+\n",
      "|94.43733659950782|253.53316003729896|57.75923155194011|3.6763717934076205|2.568403676405837 |116.38365330258377|4.578448935992045|43.40608201452739 |7.861799360135881|266.3388894075642 |990.7806538716634|30.034918577008806|18.27002825094864 |4.0 |Spring|Shenzhen|36.26812184334398 |112.19925058106232|Sunday     |2.0 |7.0  |2016.0|Haze             |58        |\n",
      "|194.1747895640595|165.60502376895855|75.11740343127136|22.24319891175683 |1.5288234811020855|178.42855969577374|37.33224995697968|27.446097018489127|9.742233348540367|27.266464519390603|994.6163340629508|47.45427695794551 |2.0491261169021873|48.0|Spring|Shanghai|48.629079983871776|105.23830183770646|Monday     |17.0|11.0 |2017.0|Cloudy           |18        |\n",
      "+-----------------+------------------+-----------------+------------------+------------------+------------------+-----------------+------------------+-----------------+------------------+-----------------+------------------+------------------+----+------+--------+------------------+------------------+-----------+----+-----+------+-----------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from chinaAirPolution.china_air_pollution\").limit(2).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e3f4c6a-212e-4085-82ce-865211c7599e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
